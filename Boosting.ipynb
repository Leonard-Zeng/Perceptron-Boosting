{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CSE151A HW5\n",
    "Zheng Zeng A14679117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Firstly, importing libraries and data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "train_data = np.genfromtxt(fname=\"pa5train.txt\", dtype=float, delimiter=' ')\n",
    "test_data = np.genfromtxt(fname=\"pa5test.txt\", dtype=float, delimiter=' ')\n",
    "dictionary = np.genfromtxt(fname=\"pa5dictionary.txt\", dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Start to implement Boosting Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def weak_learner(train_set, weights):\n",
    "    ans = {'idx': -1, 'err': 1, 'classifier': ''}\n",
    "    for j in range(4003):\n",
    "        err_plus = 0\n",
    "        err_minus = 0\n",
    "        for i in range(len(train_set)):\n",
    "            # if word i occurs, predict 1\n",
    "            if train_set[i][j] == 1:\n",
    "                plus_prediction = 1\n",
    "            else:\n",
    "                plus_prediction = -1\n",
    "            if plus_prediction != train_set[i][4003]:\n",
    "                err_plus += weights[i]\n",
    "            # if word i does not occur, predict 1\n",
    "            if train_set[i][j] == 0:\n",
    "                minus_prediction = 1\n",
    "            else:\n",
    "                minus_prediction = -1\n",
    "            if minus_prediction != train_set[i][4003]:\n",
    "                err_minus += weights[i]\n",
    "        if err_plus < ans['err']:\n",
    "            ans['idx'] = j\n",
    "            ans['err'] = err_plus\n",
    "            ans['classifier'] = 'plus'\n",
    "        if err_minus < ans['err']:\n",
    "            ans['idx'] = j\n",
    "            ans['err'] = err_minus\n",
    "            ans['classifier'] = 'minus'\n",
    "    return ans\n",
    "\n",
    "def cal_weights(train_set, weights, a_t, h_t, flag):\n",
    "    new_weights = np.zeros(len(train_set))\n",
    "    weights_sum = 0\n",
    "    for i in range(len(train_set)):\n",
    "        # firstly calculate the prediction\n",
    "        if flag == 'plus':\n",
    "            if train_set[i][h_t] == 1:\n",
    "                prediction = 1\n",
    "            else:\n",
    "                prediction = -1\n",
    "        else:\n",
    "            if train_set[i][h_t] == 0:\n",
    "                prediction = 1\n",
    "            else:\n",
    "                prediction = -1\n",
    "        new_weights[i] = weights[i] * math.exp(-1 * a_t * train_set[i][4003] * prediction)\n",
    "        weights_sum += new_weights[i]\n",
    "    new_weights /= weights_sum\n",
    "    return new_weights\n",
    "\n",
    "def boosting(train_set, weights, num_round):\n",
    "    d = [weights]\n",
    "    h = []\n",
    "    a = []\n",
    "    for t in range(num_round):\n",
    "        learner = weak_learner(train_set, d[t])\n",
    "        h_t = {'idx':learner['idx'], 'flag':learner['classifier']}\n",
    "        e_t = learner['err'] \n",
    "        a_t = 1/2*math.log((1-e_t)/e_t, math.e)\n",
    "        new_weights = cal_weights(train_set, d[t], a_t, h_t['idx'], learner['classifier'])\n",
    "        d.append(new_weights)\n",
    "        h.append(h_t)\n",
    "        a.append(a_t)\n",
    "    return {'a':np.asarray(a), 'h':np.asarray(h), 'weights':np.asarray(d)}\n",
    "     \n",
    "def predict(data, a, h):\n",
    "    sign_check = 0\n",
    "    for i in range(len(h)):\n",
    "        if h[i]['flag'] == 'plus':\n",
    "            if data[int(h[i]['idx'])] == 1:\n",
    "                prediction = 1\n",
    "            else:\n",
    "                prediction = -1\n",
    "        else:\n",
    "            if data[int(h[i]['idx'])] == 0:\n",
    "                prediction = 1\n",
    "            else:\n",
    "                prediction = -1\n",
    "        sign_check += a[i] * prediction\n",
    "    if sign_check > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def err(test_set, boost):\n",
    "    err_cnt = 0\n",
    "    for i in range(len(test_set)):\n",
    "        prediction = predict(test_set[i][:4003], boost['a'], boost['h'])\n",
    "        if prediction != test_set[i][4003]:\n",
    "            err_cnt += 1\n",
    "    return err_cnt/len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "initial_weights = np.ones(len(train_data))\n",
    "initial_weights /= len(train_data)\n",
    "boost = boosting(train_data, initial_weights, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Firstly, testing the correctness of the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051111111111111114\n",
      "0.03875968992248062\n"
     ]
    }
   ],
   "source": [
    "print(err(train_data, boost))\n",
    "print(err(test_data, boost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 3, training error: 0.064444, testing error 0.038760\n",
      "t: 7, training error: 0.028889, testing error 0.031008\n",
      "t: 10, training error: 0.015556, testing error 0.038760\n",
      "t: 15, training error: 0.000000, testing error 0.023256\n",
      "t: 20, training error: 0.000000, testing error 0.023256\n"
     ]
    }
   ],
   "source": [
    "#df = pd.DataFrame(columns = {'t', 'training error', 'testing error'})\n",
    "initial_weights = np.ones(len(train_data))\n",
    "initial_weights /= len(train_data)\n",
    "boost = boosting(train_data, initial_weights, 3)\n",
    "#df.append({\"t\":3, \"training error\":err(train_data, boost), \"testing error\":err(test_data, boost)}, ignore_index=True)\n",
    "print(\"t: %d, training error: %f, testing error %f\" % (3, err(train_data, boost), err(test_data, boost)))\n",
    "\n",
    "initial_weights = np.ones(len(train_data))\n",
    "initial_weights /= len(train_data)\n",
    "boost = boosting(train_data, initial_weights, 7)\n",
    "#df.append({\"t\":7, \"training error\":err(train_data, boost), \"testing error\":err(test_data, boost)}, ignore_index=True)\n",
    "print(\"t: %d, training error: %f, testing error %f\" % (7, err(train_data, boost), err(test_data, boost)))\n",
    "\n",
    "initial_weights = np.ones(len(train_data))\n",
    "initial_weights /= len(train_data)\n",
    "boost = boosting(train_data, initial_weights, 10)\n",
    "#df.append({\"t\":10, \"training error\":err(train_data, boost), \"testing error\":err(test_data, boost)}, ignore_index=True)\n",
    "print(\"t: %d, training error: %f, testing error %f\" % (10, err(train_data, boost), err(test_data, boost)))\n",
    "\n",
    "initial_weights = np.ones(len(train_data))\n",
    "initial_weights /= len(train_data)\n",
    "boost = boosting(train_data, initial_weights, 15)\n",
    "#df.append({\"t\":15, \"training error\":err(train_data, boost), \"testing error\":err(test_data, boost)}, ignore_index=True)\n",
    "print(\"t: %d, training error: %f, testing error %f\" % (15, err(train_data, boost), err(test_data, boost)))\n",
    "\n",
    "initial_weights = np.ones(len(train_data))\n",
    "initial_weights /= len(train_data)\n",
    "boost = boosting(train_data, initial_weights, 20)\n",
    "#df.append({\"t\":20, \"training error\":err(train_data, boost), \"testing error\":err(test_data, boost)}, ignore_index=True)\n",
    "print(\"t: %d, training error: %f, testing error %f\" % (20, err(train_data, boost), err(test_data, boost)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Problem2\n",
    "Finding the first ten indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keys = []\n",
    "for i in range(10):\n",
    "    key = boost['h'][i]['idx']\n",
    "    keys.append(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then, print out the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove (3018)\n",
      "language (2001)\n",
      "free (1423)\n",
      "university (3783)\n",
      "money (2339)\n",
      "linguistic (2089)\n",
      "click (620)\n",
      "fax (1328)\n",
      "want (3899)\n",
      "de (886)\n"
     ]
    }
   ],
   "source": [
    "for key in keys:\n",
    "    print(\"%s (%d)\"%(dictionary[key], key))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}